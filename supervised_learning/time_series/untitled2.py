# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TmxKsPE00UcK6UAfyo1ObSRcWvJIO30r
"""

!python /content/extrct.py  /content/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv.zip

import tensorflow as tf
import numpy as np
import pandas as pd
import tensorflow.keras as K
from preprocess_data import Data
import matplotlib.pyplot as plt

csv_path = '/content/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv'
data_processor = Data(csv_path)
X_t, Y_t, X_v, Y_v, X_testt, Y_testt, data, price = data_processor.full_process()
min_indice, max_indice = data_processor.classify_data(data)



def data_to_window(data, window_size):
    num_windows = len(data) - window_size
    if num_windows > 0:
        windows = np.zeros((num_windows, window_size, data.shape[1]))
        for i in range(num_windows):
            windows[i] = data[i:i + window_size]
        return windows

def output_to_window(data, window_size):
    num_windows = len(data) - window_size
    if num_windows > 0:
        windows = np.zeros((num_windows, window_size, 1))
        for i in range(num_windows):
            windows[i] = data[i:i + window_size].reshape(window_size, 1)
        return windows

train_Y = Y_t.values
val_Y = Y_v.values
test_Y = Y_testt.values

X_train = data_to_window(X_t , 10)
Y_train = output_to_window(train_Y, 10)
X_val = data_to_window(X_v, 10)
Y_val = output_to_window(val_Y, 10)
X_test = data_to_window(X_testt, 10)
Y_test = output_to_window(test_Y, 10)

print("X_train size: ", X_train.shape[0] if X_train is not None else None)
print("Y_train size: ", Y_train.shape[0] if Y_train is not None else None)

print("X_val size: ", X_val.shape[0] if X_val is not None else None)
print("Y_val size: ", Y_val.shape[0] if Y_val is not None else None)

model = K.Sequential()
model.add(K.layers.LSTM(units=64, input_shape=(
    10, X_train.shape[2]), return_sequences=True, trainable=True))
# firt two layers are trainable for only ascending trend
model.add(K.layers.Dropout(0.2))
model.add(K.layers.LSTM(units=32, return_sequences=True, trainable=True))
model.add(K.layers.Dropout(0.2))
# last two layers are  trainable for only descending trend
model.add(K.layers.LSTM(units=64,return_sequences=True, trainable=False))
model.add(K.layers.Dropout(0.2))
model.add(K.layers.LSTM(units=32, return_sequences=False, trainable=False))
model.add(K.layers.Dropout(0.2))
model.add(K.layers.Dense(units=1, activation='linear'))

model.compile(optimizer='adam', loss='mean_squared_error')

X_t2, Y_t2, X_v2, Y_v2, X_testt2, Y_testt2, data2, price2 = data_processor.full_process(up = False)

callbacks = []
def scheduler(epoch , alpha = 0.001 , decay_rate = 1):
            """scheduler function for learning rate decay"""
            return alpha / (1 + decay_rate * epoch)

callbacks.append(K.callbacks.LearningRateScheduler(scheduler, verbose=1))

history_asc = model.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data=(X_val, Y_val),callbacks=callbacks)

model.save('models/btc_model_asc.h5')  # Save the ascending trend model

train_Y = Y_t2.values
val_Y = Y_v2.values
test_Y = Y_testt2.values

X_train = data_to_window(X_t2 , 10)
Y_train = output_to_window(train_Y, 10)
X_val = data_to_window(X_v2, 10)
Y_val = output_to_window(val_Y, 10)
X_test = data_to_window(X_testt2, 10)
Y_test = output_to_window(test_Y, 10)

filename = '/content/models/btc_model_asc.h5'

model_desc = K.models.load_model(filename)

for layer in model_desc.layers:
    if layer.trainable == True:
        layer.trainable = False
    elif layer.trainable == False:
        layer.trainable = True

model_desc.compile(optimizer='adam', loss ='mean_squared_error')

history_asc = model_desc.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data=(X_val, Y_val),callbacks=callbacks)